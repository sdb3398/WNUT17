# WNUT17

## Prediction of IOB-Tags

This is a project that I conducted with 3 master's colleagues. We analyze the dataset for the WNUT 17 Emerging Entities task [This is the link](https://github.com/nluninja/nlp_datasets/tree/main/WNUT17/data). It contains text from Twitter, Stack Overflow responses, YouTube comments, and Reddit comments.
We use the two dataset 'train' and 'test' for computing the analysis. Both of them are in the IOB format (inside, outside, beginning).

### DATA STORING
In this section we upload the two dataset train and test. We concatenate the two dataframes in order to obtain a unique one with all the words and IOB tags stored.

### DATA VISUALIZATION
Visual representazion of our data: 
- first of all we create a **word cloud** of our text dataset superimposing the words onto a mask of a famous bird.
  
  ![](images/wc_bird.png)
  
- we plot a **waffle chart** that represents the proportions of different IOB tags in our dataset.
  
  ![WAFFLE CHART](images/waffle_chart.png)

- at the end we develop an interactive dashboard to facilitate the visualization of various plots. The dashboard features a left-hand menu where users can select the desired graph by clicking on its title. Subsequently, the corresponding graph will be displayed on the right-hand side. Within this dashboard, users have access to two histograms representing the lengths of sentences â€“ one encompassing all words and the other excluding stopwords. Additionally, two bar charts are included to illustrate the frequency distribution of various IOB tags, with values organized in ascending order. The first one includes all IOB tags, the second is done without the 'O' tag for the same reasons of the waffle chart.

###  Comparison between our IOB tags and the SpaCy model

The objective of this workflow is to utilize SpaCy's capabilities to efficiently identify, categorize, and extract entities and their types from textual data and then do a comparison between our IOB tags and the SpaCy model.

To quantitatively assess the accuracy of entity identification we determine the common entities between two separate datasets (the original one and the one of spacy). The calculated accuracy metric helps to judge the alignment of the datasets.

The evaluation of SpaCy's entity labeling accuracy reveals an achieved accuracy of 42.45%. Meaning the alignment between the labels generated by SpaCy and the original dataset's labels for common entities.

### NEURAL NETWORK APPROACH FOR THE NLP USE CASE

### LSTM FOR NER

We implement this model in two situations: lower case and upper case. The results are very similar.

The model predicts the tag 'O' very often





